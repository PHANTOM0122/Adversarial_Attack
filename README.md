# Adversarial_Attack
Implementing Adversarial attacks with various datasets and architectures

# Attack algorithms
1) **FGSM** : Fast Gradient Sign Method <br>
<img src=https://user-images.githubusercontent.com/50229148/127620244-3705732c-a750-4c9d-abe7-f4dc0a191428.png width="800" height="300">

The fast gradient sign method works by using the gradients of the neural network to create an adversarial example. For an input image, the method uses the gradients of the loss with respect to the input image to create a new image that maximises the loss. This new image is called the adversarial image. This can be summarised using the following expression:

2) **UAP** : Universal Adversarial Perturbation
3) **DeepFool**

# Datasets
1) Cifar10


# DNN Architectures
1) **AlexNet**
2) **VGG-16**
3) **ResNet-50**
